{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ready-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afraid-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gc\n",
    "import timeit\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from random import normalvariate\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd02bec-4210-48b0-8127-ded93bfb9d24",
   "metadata": {},
   "source": [
    "# Prepare the synthetic observation vector for all municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3058844b-c538-44a6-bb65-dbb787184a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_synt_obs(municipality, df_top_hits, c_v, semi_average):\n",
    "    save_dir = \"synthetic_data/\"\n",
    "    df_municipality = pd.read_pickle(save_dir + municipality)\n",
    "    pop = np.zeros((20, 15))\n",
    "    for i in range(20):\n",
    "        parameter = df_top_hits.iloc[i, 0:9]\n",
    "        df_hits = df_municipality.loc[\n",
    "            (df_municipality[\"init_pop\"] == parameter[0])\n",
    "            & (df_municipality[\"init_hps\"] == parameter[1])\n",
    "            & (df_municipality[\"sh_threshold\"] == parameter[2])\n",
    "            & (df_municipality[\"i_fcalves\"] == parameter[3])\n",
    "            & (df_municipality[\"i_yhinds\"] == parameter[4])\n",
    "            & (df_municipality[\"i_ahinds\"] == parameter[5])\n",
    "            & (df_municipality[\"i_mcalves\"] == parameter[6])\n",
    "            & (df_municipality[\"i_ystags\"] == parameter[7])\n",
    "            & (df_municipality[\"i_astags\"] == parameter[8])\n",
    "        ].copy()\n",
    "        pop[i, :] = df_hits.iloc[:, 17].values\n",
    "\n",
    "    pop_bh = np.median(pop, axis=0)\n",
    "\n",
    "    # Ensure that the sampling gives a correct c_v and semi_average value\n",
    "    CV = 0\n",
    "    SA = 0\n",
    "    while (abs(c_v - CV) > 0.01) & (abs(semi_average - SA) > 0.1 * semi_average):\n",
    "        synt_obs = np.zeros(15)\n",
    "        for i in range(15):\n",
    "            synt_obs[i] = normalvariate(pop_bh[i], pop_bh[i] * c_v)\n",
    "\n",
    "        CV = np.std(synt_obs) / np.mean(synt_obs)\n",
    "        SA = synt_obs[8:15].mean() / synt_obs[0:7].mean()\n",
    "\n",
    "    # Scale synt_obs around 1.0\n",
    "    synt_obs_scaled = synt_obs / np.mean(synt_obs)\n",
    "    return synt_obs_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-southeast",
   "metadata": {},
   "source": [
    "# Residual Sum of Squares calculations: synthetic data against data for seen deer per hunting hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generic-accordance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revoking stored reported data\n",
    "# https://ipython.org/ipython-doc/rel-0.12/config/extensions/storemagic.html\n",
    "\n",
    "%store -r data_Averoy\n",
    "%store -r data_Tingvoll\n",
    "%store -r data_Surnadal\n",
    "%store -r data_Sunndal\n",
    "%store -r data_Vestnes\n",
    "%store -r data_Laerdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "listed-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_squares_seen_deer(\n",
    "    number_of_years,\n",
    "    municipality_file,\n",
    "    empirical_observations,\n",
    "    compare,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculating the minimum residual_sum_of_squares between synthetic data and\n",
    "    reported data\n",
    "    \"\"\"\n",
    "\n",
    "    # Revoking the targeted municipality data frame created by the synthetic population generator\n",
    "    save_dir = \"synthetic_data/\"\n",
    "    data_frame = pd.read_pickle(save_dir + municipality_file)\n",
    "\n",
    "    # Defining column to extract values from\n",
    "    if compare == \"before_hunting\":\n",
    "        comp_choice = \"tot_pop_bh\"\n",
    "    if compare == \"after_hunting\":\n",
    "        comp_choice = \"tot_pop_ah\"\n",
    "\n",
    "    RSS_list = []\n",
    "    for i in range(0, int(len(data_frame) / number_of_years)):\n",
    "        # Catch the predicted total population sizes for all observation years\n",
    "        seen_deer_p = data_frame.iloc[i * number_of_years : (i + 1) * number_of_years][\n",
    "            comp_choice\n",
    "        ].values\n",
    "\n",
    "        seen_deer_e = empirical_observations\n",
    "\n",
    "        # Find the scaling factor that minimises RSS and do the scaling\n",
    "        scaling_factor = np.sum(np.multiply(seen_deer_p, seen_deer_e)) / np.sum(\n",
    "            np.multiply(seen_deer_p, seen_deer_p)\n",
    "        )\n",
    "        seen_deer_p_scaled = scaling_factor * seen_deer_p\n",
    "\n",
    "        # Find minimum Residual Sum Square value\n",
    "        RSS_min = np.sum((seen_deer_p_scaled - seen_deer_e) ** 2)\n",
    "\n",
    "        RSS_list.append([scaling_factor, RSS_min])\n",
    "\n",
    "    return RSS_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eleven-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_RSS_frame(municipality_file, RSS_list):\n",
    "\n",
    "    # Revoking the targeted municipality data frame created by the synthetic population generator\n",
    "    save_dir = \"synthetic_data/\"\n",
    "    data_frame = pd.read_pickle(save_dir + municipality_file)\n",
    "\n",
    "    # Remove all rows except those where obs_year == 2021\n",
    "    df_filtered = data_frame[data_frame[\"obs_year\"] == 2021]\n",
    "\n",
    "    # Remove columns not used\n",
    "    cols = [\n",
    "        \"f_calves\",\n",
    "        \"y_hinds\",\n",
    "        \"a_hinds\",\n",
    "        \"m_calves\",\n",
    "        \"y_stags\",\n",
    "        \"a_stags\",\n",
    "        \"ws_fc\",\n",
    "        \"ws_yh\",\n",
    "        \"ws_ah\",\n",
    "        \"ws_mc\",\n",
    "        \"ws_ys\",\n",
    "        \"ws_as\",\n",
    "        \"c_yh\",\n",
    "        \"c_ah\",\n",
    "    ]\n",
    "    df_filtered2 = df_filtered.drop(cols, axis=1)\n",
    "\n",
    "    # Resert index, otherwise pd.concat does not work\n",
    "    df_filtered2 = df_filtered2.reset_index(drop=True)\n",
    "\n",
    "    # Add two columns from RSS_list\n",
    "    df_RSS = pd.concat(\n",
    "        [df_filtered2, pd.DataFrame(RSS_list, columns=[\"scaling\", \"RSS\"])], axis=1\n",
    "    )\n",
    "\n",
    "    # Sort the frame on the RSS value\n",
    "    sorted_sum_squares_frame = df_RSS.sort_values(by=[\"RSS\"]).reset_index(drop=True)\n",
    "\n",
    "    return sorted_sum_squares_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "clean-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_top_hits(\n",
    "    i,\n",
    "    sorted_sum_squares_frame,\n",
    "    filtering_strategy,\n",
    "    frac_init_pop,\n",
    "    number_of_top_hits,\n",
    "):\n",
    "    \"\"\"\n",
    "    Filtering the sum_squares frame based on an assumption about the\n",
    "    size of the Dec 31 2020 population vs the Dec 31 2006 population,\n",
    "    and delivering only the number_of_top_hits best fits.\n",
    "    \"\"\"\n",
    "\n",
    "    if filtering_strategy == \"uninformed\":\n",
    "        sorted_sum_squares_frame_filtered = sorted_sum_squares_frame\n",
    "\n",
    "    if filtering_strategy == \"informed\":\n",
    "        # Educated guess filtering - can play with these criteria\n",
    "        sorted_sum_squares_frame_filtered = sorted_sum_squares_frame[\n",
    "            (\n",
    "                sorted_sum_squares_frame.tot_pop_ah\n",
    "                > frac_init_pop[i] * sorted_sum_squares_frame.init_pop\n",
    "            )\n",
    "        ].reset_index(drop=True)\n",
    "\n",
    "    return sorted_sum_squares_frame_filtered[0:number_of_top_hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nominated-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_the_show():\n",
    "    global tot_pop_ah_collected\n",
    "    tot_pop_ah_collected = []\n",
    "    save_dir = \"synthetic_data/\"\n",
    "\n",
    "    # Coefficient of variation of the original seen-deer vectors + semi-average values\n",
    "    # Data calculated in Figure1_..\n",
    "    c_v = [0.218, 0.110, 0.308, 0.151, 0.164, 0.179]\n",
    "    semi_average_seen_deer = [0.838, 1.008, 0.864, 1.011, 0.942, 1.041]\n",
    "\n",
    "    # Using all 6 municipalities\n",
    "    municipalities = [\"Averoy\", \"Tingvoll\", \"Surnadal\", \"Sunndal\", \"Vestnes\", \"Laerdal\"]\n",
    "    data_municipality = [\n",
    "        data_Averoy,\n",
    "        data_Tingvoll,\n",
    "        data_Surnadal,\n",
    "        data_Sunndal,\n",
    "        data_Vestnes,\n",
    "        data_Laerdal,\n",
    "    ]\n",
    "\n",
    "    top_hits_Averoy_seen_deer = pd.read_pickle(\n",
    "        save_dir + \"top_hits_Averoy_seen_deer.pkl\"\n",
    "    )\n",
    "    top_hits_Tingvoll_seen_deer = pd.read_pickle(\n",
    "        save_dir + \"top_hits_Tingvoll_seen_deer.pkl\"\n",
    "    )\n",
    "    top_hits_Surnadal_seen_deer = pd.read_pickle(\n",
    "        save_dir + \"top_hits_Surnadal_seen_deer.pkl\"\n",
    "    )\n",
    "    top_hits_Sunndal_seen_deer = pd.read_pickle(\n",
    "        save_dir + \"top_hits_Sunndal_seen_deer.pkl\"\n",
    "    )\n",
    "    top_hits_Vestnes_seen_deer = pd.read_pickle(\n",
    "        save_dir + \"top_hits_Vestnes_seen_deer.pkl\"\n",
    "    )\n",
    "    top_hits_Laerdal_seen_deer = pd.read_pickle(\n",
    "        save_dir + \"top_hits_Laerdal_seen_deer.pkl\"\n",
    "    )\n",
    "\n",
    "    municipality_frame = [\n",
    "        \"df_original_sorted_Averoy.pkl\",\n",
    "        \"df_original_sorted_Tingvoll.pkl\",\n",
    "        \"df_original_sorted_Surnadal.pkl\",\n",
    "        \"df_original_sorted_Sunndal.pkl\",\n",
    "        \"df_original_sorted_Vestnes.pkl\",\n",
    "        \"df_original_sorted_Laerdal.pkl\",\n",
    "    ]\n",
    "\n",
    "    top_hits_seen_deer = [\n",
    "        top_hits_Averoy_seen_deer,\n",
    "        top_hits_Tingvoll_seen_deer,\n",
    "        top_hits_Surnadal_seen_deer,\n",
    "        top_hits_Sunndal_seen_deer,\n",
    "        top_hits_Vestnes_seen_deer,\n",
    "        top_hits_Laerdal_seen_deer,\n",
    "    ]\n",
    "\n",
    "    compare = \"before_hunting\"\n",
    "    filtering_strategy = \"informed\"\n",
    "    frac_init_pop = [0.8] * len(municipalities)  # minumum tot_pop 2020/2006 ratio\n",
    "    number_of_top_hits = 20\n",
    "\n",
    "    for k in range(10):\n",
    "        print(\"k = \", k)\n",
    "        tot_pop_ah = []\n",
    "        for q in range(len(municipalities)):\n",
    "            [\n",
    "                municipality,\n",
    "                first_year,\n",
    "                last_year,\n",
    "                number_of_years,\n",
    "                years,\n",
    "                seen_deer_obs,\n",
    "                seen_deer_obs_outfield,\n",
    "                seen_deer_obs_infield,\n",
    "                hinds_per_stag_obs,\n",
    "                total_harvest,\n",
    "                fraction_female_calves_harvested,\n",
    "                fraction_young_hinds_harvested,\n",
    "                fraction_adult_hinds_harvested,\n",
    "                fraction_male_calves_harvested,\n",
    "                fraction_young_stags_harvested,\n",
    "                fraction_adult_stags_harvested,\n",
    "                spring_counts,\n",
    "            ] = data_municipality[q]\n",
    "\n",
    "            # Make synthetic observation record for the given municipality\n",
    "            synt_obs_scaled = make_synt_obs(\n",
    "                municipality_frame[q],\n",
    "                top_hits_seen_deer[q],\n",
    "                c_v[q],\n",
    "                semi_average_seen_deer[q],\n",
    "            )\n",
    "\n",
    "            RSS_list = sum_squares_seen_deer(\n",
    "                number_of_years,\n",
    "                municipality_frame[q],\n",
    "                synt_obs_scaled,\n",
    "                compare,\n",
    "            )\n",
    "\n",
    "            sorted_sum_squares_frame = make_RSS_frame(municipality_frame[q], RSS_list)\n",
    "\n",
    "            top_hits_frame_filtered = extract_top_hits(\n",
    "                q,\n",
    "                sorted_sum_squares_frame,\n",
    "                filtering_strategy,\n",
    "                frac_init_pop,\n",
    "                number_of_top_hits,\n",
    "            )\n",
    "\n",
    "            # Extract post-hunt median population size\n",
    "            tot_pop_ah.append(np.median(top_hits_frame_filtered[\"tot_pop_ah\"].values))\n",
    "\n",
    "        tot_pop_ah_collected.append(tot_pop_ah)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "protected-anxiety",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k =  0\n",
      "k =  1\n",
      "k =  2\n",
      "k =  3\n",
      "k =  4\n",
      "k =  5\n",
      "k =  6\n",
      "k =  7\n",
      "k =  8\n",
      "k =  9\n",
      "CPU times: user 1d 16h 12min 16s, sys: 3h 15min 29s, total: 1d 19h 27min 45s\n",
      "Wall time: 1d 19h 33min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Running all scripts by calling up run_the_show\n",
    "# This is done to get rid of memory leaks\n",
    "run_the_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cf59a92-25e1-4d0c-bd7a-746e2954459f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1022. , 2505. , 1445. , 2221.5, 1791.5, 1560.5],\n",
       "       [1039.5, 2118.5, 1513. , 1592. , 2240.5, 1483. ],\n",
       "       [1027. , 2237. , 1264.5, 1630.5, 1804.5, 1363.5],\n",
       "       [1129.5, 2214.5, 1323.5, 2185. , 1850. , 1686. ],\n",
       "       [1013. , 2242.5, 1521. , 1680. , 2061.5, 1843. ],\n",
       "       [1013. , 2660. , 2496. , 1900.5, 2089.5, 1460. ],\n",
       "       [1020. , 2298.5, 1574. , 1823.5, 2465. , 1306. ],\n",
       "       [1099.5, 1988. , 1490. , 1584.5, 2264. , 1395. ],\n",
       "       [1032. , 2200.5, 2135.5, 1942. , 2185. , 1912. ],\n",
       "       [1051.5, 2103. , 1534. , 2272.5, 1620.5, 1970. ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tot_pop_ah_collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb4f7e8-eb12-4751-84ec-c123b987e0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
